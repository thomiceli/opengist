package index

import (
	"errors"
	"strconv"
	// "fmt"
	"strings"

	"github.com/blevesearch/bleve/v2"
	"github.com/blevesearch/bleve/v2/analysis/analyzer/custom"
	"github.com/blevesearch/bleve/v2/analysis/token/camelcase"
	"github.com/blevesearch/bleve/v2/analysis/token/length"
	"github.com/blevesearch/bleve/v2/analysis/token/lowercase"
	"github.com/blevesearch/bleve/v2/analysis/token/unicodenorm"
	// "github.com/blevesearch/bleve/v2/analysis/tokenizer/unicode"

	bleveUnicode "github.com/blevesearch/bleve/v2/analysis/tokenizer/unicode"
	"github.com/blevesearch/bleve/v2/search/query"
	"github.com/rs/zerolog/log"
)

type BleveIndexer struct {
	index bleve.Index
	path  string
}

func NewBleveIndexer(path string) *BleveIndexer {
	return &BleveIndexer{path: path}
}

func (i *BleveIndexer) Init() error {
	errChan := make(chan error, 1)

	go func() {
		bleveIndex, err := i.open()
		if err != nil {
			log.Error().Err(err).Msg("Failed to open Bleve index")
			i.Close()
			errChan <- err
			return
		}
		i.index = bleveIndex
		log.Info().Msg("Bleve indexer initialized")
		errChan <- nil
	}()

	return <-errChan
}

func (i *BleveIndexer) open() (bleve.Index, error) {
	bleveIndex, err := bleve.Open(i.path)
	if err == nil {
		return bleveIndex, nil
	}

	if !errors.Is(err, bleve.ErrorIndexPathDoesNotExist) {
		return nil, err
	}

	// ==========================================
    // 1. å®šä¹‰ç´¢å¼•è§„åˆ™ (Mapping)
	mapping := bleve.NewIndexMapping()

	// å®šä¹‰è¿‡æ»¤å™¨ï¼šå»é™¤é•¿åº¦å°äº 2 çš„æ— æ„ä¹‰å­—ç¬¦ (å¦‚ a, b, 1)
	if err = mapping.AddCustomTokenFilter("length_filter_min2", map[string]interface{}{
		"type": length.Name,
		"min":  2.0,
	}); err != nil {
		return nil, err
	}

	// å®šä¹‰è¿‡æ»¤å™¨ï¼šUnicode æ ‡å‡†åŒ–
	if err = mapping.AddCustomTokenFilter("unicodeNormalize", map[string]any{
		"type": unicodenorm.Name,
		"form": unicodenorm.NFC,
	}); err != nil {
		return nil, err
	}

	// --- åˆ†æå™¨ 1: ã€æ‹†åˆ†æ¨¡å¼ã€‘ (ç”¨äºæœå±€éƒ¨) æ•ˆæœ: "UserLogin" -> "user", "login" ---
	if err = mapping.AddCustomAnalyzer("code_split", map[string]interface{}{
		"type":      custom.Name,
		"tokenizer": bleveUnicode.Name,
		"token_filters": []string{
			"unicodeNormalize",
			camelcase.Name,       // æ ¸å¿ƒï¼šæ‹†åˆ†é©¼å³°
			lowercase.Name,       // è½¬å°å†™
			"length_filter_min2", // å»æ‰æ‹†åˆ†åå¤ªçŸ­çš„
		},
	}); err != nil {
		return nil, err
	}

	// --- åˆ†æå™¨ 2: ã€ç²¾ç¡®æ¨¡å¼ã€‘ (ç”¨äºæœå…¨è¯) æ•ˆæœ: "UserLogin" -> "userlogin" ---
	if err = mapping.AddCustomAnalyzer("code_exact", map[string]interface{}{
		"type":      custom.Name,
		"tokenizer": bleveUnicode.Name,
		"token_filters": []string{
			"unicodeNormalize",
			lowercase.Name,       // åªè½¬å°å†™ï¼Œä¸æ‹†åˆ†ï¼
			"length_filter_min2",
		},
	}); err != nil {
		return nil, err
	}

	docMapping := bleve.NewDocumentMapping()
	// æ•°å€¼å­—æ®µ
	docMapping.AddFieldMappingsAt("GistID", bleve.NewNumericFieldMapping())
	docMapping.AddFieldMappingsAt("UserID", bleve.NewNumericFieldMapping())
	docMapping.AddFieldMappingsAt("Visibility", bleve.NewNumericFieldMapping())

	// Metadata å­—æ®µ (æ ‡é¢˜ã€æ–‡ä»¶åç­‰ï¼Œé€šå¸¸é€‚åˆæ‹†åˆ†æœ)
	metaMapping := bleve.NewTextFieldMapping()
	metaMapping.Analyzer = "code_split"
	docMapping.AddFieldMappingsAt("Username", metaMapping)
	docMapping.AddFieldMappingsAt("Title", metaMapping)
	docMapping.AddFieldMappingsAt("Filenames", metaMapping)
	docMapping.AddFieldMappingsAt("Extensions", metaMapping)
	docMapping.AddFieldMappingsAt("Languages", metaMapping)
	docMapping.AddFieldMappingsAt("Topics", metaMapping)


	// --- æ ¸å¿ƒ Content å­—æ®µçš„åŒé‡æ˜ å°„ ---
    
    // æ˜ å°„ A: Content (ç²¾ç¡®åŒ¹é…) å­˜: "userlogin"
	contentExact := bleve.NewTextFieldMapping()
	contentExact.Name = "Content" // å­—æ®µå
	contentExact.Analyzer = "code_exact"
	contentExact.Store = false
	contentExact.IncludeTermVectors = true

	// æ˜ å°„ B: ContentSplit (æ‹†åˆ†åŒ¹é…) å­˜: "user", "login"
	contentSplit := bleve.NewTextFieldMapping()
	contentSplit.Name = "ContentSplit" // è™šæ‹Ÿå­—æ®µå
	contentSplit.Analyzer = "code_split"
	contentSplit.Store = false
	contentSplit.IncludeTermVectors = true

	// å°†åŒä¸€ä¸ª Content å†…å®¹ï¼ŒåŒæ—¶å¡è¿›è¿™ä¸¤ä¸ªæ˜ å°„é‡Œ
	docMapping.AddFieldMappingsAt("Content", contentExact, contentSplit)
	mapping.DefaultMapping = docMapping
	return bleve.New(i.path, mapping)
}


func (i *BleveIndexer) Close() {
	if i == nil || i.index == nil {
		return
	}

	err := i.index.Close()
	if err != nil {
		log.Error().Err(err).Msg("Failed to close Bleve index")
	}
	log.Info().Msg("Bleve indexer closed")
}

func (i *BleveIndexer) Add(gist *Gist) error {
	if gist == nil {
		return errors.New("failed to add nil gist to index")
	}
	return (*atomicIndexer.Load()).(*BleveIndexer).index.Index(strconv.Itoa(int(gist.GistID)), gist)
}

func (i *BleveIndexer) Remove(gistID uint) error {
	return (*atomicIndexer.Load()).(*BleveIndexer).index.Delete(strconv.Itoa(int(gistID)))
}

func (i *BleveIndexer) Search(queryStr string, queryMetadata SearchGistMetadata, userId uint, page int) ([]uint, uint64, map[string]int, error) {
	var err error
	var indexerQuery query.Query
	
	// ==========================================
    // 3. æœç´¢é€»è¾‘ (åŒæ—¶æœä¸¤ä¸ªå­—æ®µ)
	if queryStr != "" {
		queryStr = strings.ToLower(strings.TrimSpace(queryStr))

        // æŸ¥ Content (ç²¾ç¡®): æƒé‡é«˜ï¼ŒåŒ¹é… "userlogin"
		q1 := bleve.NewMatchQuery(queryStr)
		q1.SetField("Content")
		q1.SetBoost(1.5)		// âš ï¸ åˆ æ‰äº† Fuzziness=2ï¼Œä»£ç æœç´¢ä¸éœ€è¦æ¨¡ç³Š

        // æŸ¥ ContentSplit (æ‹†åˆ†): æƒé‡ä½ï¼ŒåŒ¹é… "login"
		q2 := bleve.NewMatchQuery(queryStr)
		q2.SetField("ContentSplit")
		q2.SetBoost(1.0)

        // Metadata æŸ¥è¯¢
        titleQuery := bleve.NewMatchQuery(queryStr)
        titleQuery.SetField("Title")
        titleQuery.SetBoost(3.0)

        usernameQuery := bleve.NewMatchQuery(queryStr)
        usernameQuery.SetField("Username")
        usernameQuery.SetBoost(2.0)
        
        filenameQuery := bleve.NewMatchQuery(queryStr)
        filenameQuery.SetField("Filenames")
        filenameQuery.SetBoost(2.5)

        // åªè¦æ»¡è¶³ä»»æ„ä¸€ä¸ªå³å¯ (Disjunction)
		indexerQuery = bleve.NewDisjunctionQuery(
            q1, 
            q2, 
            titleQuery,
            usernameQuery, 
            filenameQuery,
        )
	} else {
		contentQuery := bleve.NewMatchAllQuery()
		indexerQuery = contentQuery
	}

	// æƒé™è¿‡æ»¤
	visibilityZero := float64(0)
	truee := true
	publicQuery := bleve.NewNumericRangeInclusiveQuery(&visibilityZero, &visibilityZero, &truee, &truee)
	publicQuery.SetField("Visibility")

	userIdMatch := float64(userId)
	userIdQuery := bleve.NewNumericRangeInclusiveQuery(&userIdMatch, &userIdMatch, &truee, &truee)
	userIdQuery.SetField("UserID")

	accessQuery := bleve.NewDisjunctionQuery(publicQuery, userIdQuery)
	indexerQuery = bleve.NewConjunctionQuery(accessQuery, indexerQuery)

	// å¤„ç† All å’Œå…¶ä»– Metadata
	if queryMetadata.All != "" {
		allQueries := make([]query.Query, 0)
		fields := []string{"Username", "Title", "Filenames", "Languages", "Topics"}
		for _, f := range fields {
			q := bleve.NewMatchQuery(queryMetadata.All) // ç”¨ MatchQuery ä»¥æ”¯æŒåˆ†è¯
			q.SetField(f)
			allQueries = append(allQueries, q)
		}
        // Extension å•ç‹¬å¤„ç†
        extQ := bleve.NewMatchQuery("." + queryMetadata.All)
        extQ.SetField("Extensions")
        allQueries = append(allQueries, extQ)

		allDisjunction := bleve.NewDisjunctionQuery(allQueries...)
		indexerQuery = bleve.NewConjunctionQuery(indexerQuery, allDisjunction)
	} else {
		addQuery := func(field, value string) {
			if value != "" && value != "." {
				q := bleve.NewMatchQuery(value) // ç”¨ MatchQuery
				q.SetField(field)
				indexerQuery = bleve.NewConjunctionQuery(indexerQuery, q)
			}
		}
		addQuery("Username", queryMetadata.Username)
		addQuery("Title", queryMetadata.Title)
		addQuery("Extensions", "."+queryMetadata.Extension)
		addQuery("Filenames", queryMetadata.Filename)
		addQuery("Languages", queryMetadata.Language)
		addQuery("Topics", queryMetadata.Topic)
	}

	languageFacet := bleve.NewFacetRequest("Languages", 10)
	perPage := 10
	offset := (page - 1) * perPage

	s := bleve.NewSearchRequestOptions(indexerQuery, perPage+1, offset, false)
	s.AddFacet("languageFacet", languageFacet)
    
    // è¿”å›è¿™äº›å­—æ®µä»¥ä¾¿è°ƒè¯•
	s.Fields = []string{"GistID", "Title", "Username", "Filenames"}
	s.IncludeLocations = true // å¼€å¯ä½ç½®åŒ¹é…ï¼Œæ–¹ä¾¿è°ƒè¯•

	results, err := (*atomicIndexer.Load()).(*BleveIndexer).index.Search(s)
	if err != nil {
		return nil, 0, nil, err
	}

	// ==========================================
    // 4. Debug æ‰“å°
    // if queryStr != "" {
    //     fmt.Println("\n================= ğŸ” DEBUG SEARCH ================= ")
    //     fmt.Printf("å…³é”®è¯: [%s]  æ‰¾åˆ°: %d ä¸ª\n", queryStr, results.Total)
        
    //     for i, hit := range results.Hits {
    //         title := hit.Fields["Title"]
    //         // ç®€å•çš„æ‰“å°ï¼Œåªæ˜¾ç¤ºåŒ¹é…äº†å“ªäº›å­—æ®µ
    //         var matchedFields []string
    //         if hit.Locations != nil {
    //             for field := range hit.Locations {
    //                 matchedFields = append(matchedFields, field)
    //             }
    //         }
            
    //         fmt.Printf("#%d [ID:%s] Score:%.2f Title:%v åŒ¹é…å­—æ®µ:%v\n", 
    //             i+1, hit.ID, hit.Score, title, matchedFields)
    //     }
    //     fmt.Println("===================================================\n")
    // }


	gistIds := make([]uint, 0, len(results.Hits))
	for _, hit := range results.Hits {
		gistIds = append(gistIds, uint(hit.Fields["GistID"].(float64)))
	}

	languageCounts := make(map[string]int)
	if facets, found := results.Facets["languageFacet"]; found {
		for _, term := range facets.Terms.Terms() {
			languageCounts[term.Term] = term.Count
		}
	}

	return gistIds, results.Total, languageCounts, nil
}

